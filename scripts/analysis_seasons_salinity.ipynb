{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1303ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51861a41",
   "metadata": {},
   "source": [
    "## compute seasonal means of salinity using hycom raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00a3a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_inicio</th>\n",
       "      <th>fecha_fin</th>\n",
       "      <th>anio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2da 2015</th>\n",
       "      <td>2015-11-17</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ra 2016</th>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2da 2016</th>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ra 2017</th>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2da 2017</th>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ra 2018</th>\n",
       "      <td>2018-04-07</td>\n",
       "      <td>2018-06-26</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2da 2018</th>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ra 2019</th>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2da 2019</th>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ra 2020</th>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2da 2020</th>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>2021-01-24</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ra 2021</th>\n",
       "      <td>2021-04-23</td>\n",
       "      <td>2021-07-26</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2da 2021</th>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ra 2022</th>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2da 2022</th>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>2023-02-04</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ra 2023</th>\n",
       "      <td>2023-06-03</td>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2da 2023</th>\n",
       "      <td>2023-10-21</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ra 2024</th>\n",
       "      <td>2024-04-16</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fecha_inicio   fecha_fin  anio\n",
       "2da 2015   2015-11-17  2016-01-22  2015\n",
       "1ra 2016   2016-06-18  2016-07-26  2016\n",
       "2da 2016   2016-11-11  2017-01-26  2016\n",
       "1ra 2017   2017-04-22  2017-07-31  2017\n",
       "2da 2017   2017-11-23  2018-01-25  2017\n",
       "1ra 2018   2018-04-07  2018-06-26  2018\n",
       "2da 2018   2018-11-15  2019-01-14  2018\n",
       "1ra 2019   2019-04-28  2019-07-30  2019\n",
       "2da 2019   2019-11-06  2020-01-02  2019\n",
       "1ra 2020   2020-05-13  2020-07-24  2020\n",
       "2da 2020   2020-11-12  2021-01-24  2020\n",
       "1ra 2021   2021-04-23  2021-07-26  2021\n",
       "2da 2021   2021-11-15  2022-01-06  2021\n",
       "1ra 2022   2022-05-04  2022-07-23  2022\n",
       "2da 2022   2022-11-23  2023-02-04  2022\n",
       "1ra 2023   2023-06-03  2023-08-12  2023\n",
       "2da 2023   2023-10-21  2024-01-12  2023\n",
       "1ra 2024   2024-04-16  2024-06-18  2024"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fechas_temporadas = pd.read_csv(\"/home/jupyter-daniela/suyana/peru_production/outputs/calas_temporadas_fechas_inicio_fin.csv\", index_col=0)\n",
    "df_fechas_temporadas.drop(index=['temporada', np.nan], inplace=True)\n",
    "df_fechas_temporadas['anio'] = pd.to_datetime(df_fechas_temporadas['fecha_inicio']).dt.year\n",
    "\n",
    "df_fechas_temporadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c81ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2da 2015\n",
      "1ra 2016\n",
      "2da 2016\n",
      "1ra 2017\n",
      "2da 2017\n",
      "1ra 2018\n",
      "2da 2018\n",
      "1ra 2019\n",
      "2da 2019\n",
      "1ra 2020\n",
      "2da 2020\n",
      "1ra 2021\n",
      "2da 2021\n",
      "1ra 2022\n",
      "2da 2022\n",
      "1ra 2023\n",
      "2da 2023\n",
      "1ra 2024\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "path_hycom_data = Path(\"/home/jupyter-daniela/suyana/sources/hycom/\")\n",
    "\n",
    "path_features = Path(\"/home/jupyter-daniela/suyana/peru_production/features/\")\n",
    "\n",
    "\n",
    "for _, row in df_fechas_temporadas.iterrows():\n",
    "    print(row.name)\n",
    "    t0 = pd.to_datetime(row[\"fecha_inicio\"])\n",
    "    t1 = pd.to_datetime(row[\"fecha_fin\"])\n",
    "    meses = pd.period_range(t0.to_period(\"M\"), t1.to_period(\"M\"), freq=\"M\")\n",
    "\n",
    "    datasets = []\n",
    "    for m in meses:\n",
    "        f = path_hycom_data / str(m.year) / f\"hycom_{m.year}{m.month:02d}.nc\"\n",
    "        if not f.exists():\n",
    "            continue\n",
    "        ds = xr.open_dataset(f)\n",
    "        ds = ds.sel(depth=0)\n",
    "        ds = ds.sortby(\"time\")\n",
    "        ds = ds.sel(time=slice(t0, t1))\n",
    "        if ds.sizes.get(\"time\", 0) > 0:\n",
    "            datasets.append(ds)\n",
    "\n",
    "    if not datasets:\n",
    "        continue\n",
    "\n",
    "    lat_shapes = [ds.sizes[\"lat\"] for ds in datasets]\n",
    "    lon_shapes = [ds.sizes[\"lon\"] for ds in datasets]\n",
    "\n",
    "    if len(set(lat_shapes)) > 1 or len(set(lon_shapes)) > 1:\n",
    "        ds_ref = max(datasets, key=lambda d: (d.sizes[\"lat\"] * d.sizes[\"lon\"]))\n",
    "        target_lat = ds_ref[\"lat\"]\n",
    "        target_lon = ds_ref[\"lon\"]\n",
    "        datasets_interp = []\n",
    "        for ds in datasets:\n",
    "            if not (\n",
    "                ds.sizes[\"lat\"] == ds_ref.sizes[\"lat\"]\n",
    "                and ds.sizes[\"lon\"] == ds_ref.sizes[\"lon\"]\n",
    "            ):\n",
    "                ds = ds.interp(lat=target_lat, lon=target_lon)\n",
    "            datasets_interp.append(ds)\n",
    "        datasets = datasets_interp\n",
    "\n",
    "    ds_concat = xr.concat(datasets, dim=\"time\", join=\"override\")\n",
    "    nombre = str(row.name).replace(\" \", \"-\")\n",
    "    ds_concat.to_netcdf(path_features / f\"hycom_{nombre}.nc\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peru_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
