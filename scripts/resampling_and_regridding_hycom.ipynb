{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def open_and_regrid(folder_path, variable, coarse_grid_file):\n",
    "    coarse_grid = xr.open_dataset(coarse_grid_file, engine=\"netcdf4\")\n",
    "    coarse_lat = coarse_grid.lat\n",
    "    coarse_lon = coarse_grid.lon\n",
    "    files = sorted(Path(folder_path).rglob(\"*.nc\"))\n",
    "    ds_list = []\n",
    "    for f in files:\n",
    "        ds = xr.open_dataset(f, chunks={'time': -1}, engine=\"netcdf4\")\n",
    "        if ds.lat.size != coarse_lat.size:\n",
    "            ds = ds.interp(lat=coarse_lat, lon=coarse_lon)\n",
    "        ds_list.append(ds[[variable]])\n",
    "    ds_all = xr.concat(ds_list, dim=\"time\")\n",
    "    ds_all = ds_all.sortby(\"time\")\n",
    "    ds_all = ds_all.drop_duplicates(dim=\"time\")\n",
    "    return ds_all\n",
    "\n",
    "def compute_daily(ds, variable):\n",
    "    return ds[variable].resample(time=\"1D\").mean()\n",
    "\n",
    "# def compute_weekly(ds_daily):\n",
    "#     year = ds_daily.time.dt.year\n",
    "#     doy = ds_daily.time.dt.dayofyear\n",
    "#     week_in_year = ((doy - 1) // 7) + 1\n",
    "#     week_id = xr.DataArray(\n",
    "#         (year.astype(str) + \"_\" + week_in_year.astype(str)).values,\n",
    "#         coords={\"time\": ds_daily.time}, dims=\"time\"\n",
    "#     )\n",
    "#     return ds_daily.groupby(week_id).mean(dim=\"time\")\n",
    "\n",
    "# def compute_daily_climatology(ds_daily):\n",
    "#     doy = ds_daily[\"time\"].dt.dayofyear\n",
    "#     clim = ds_daily.groupby(doy).mean(\"time\")\n",
    "#     return clim\n",
    "\n",
    "# def compute_daily_anomalies(ds_daily, clim):\n",
    "#     doy = ds_daily[\"time\"].dt.dayofyear\n",
    "#     return ds_daily.groupby(doy) - clim\n",
    "\n",
    "def save_netcdf(da, dataset, variable, freq, period, area, resolution, out_dir=\"outputs\"):\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filename = f\"{dataset}_{variable}_{freq}_{period}_{area}_{resolution}.nc\"\n",
    "    da.to_netcdf(out_dir / filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93494fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2553597/1182777592.py:17: FutureWarning: In a future version of xarray the default value for join will change from join='outer' to join='exact'. This change will result in the following ValueError: cannot be aligned with join='exact' because index/labels/sizes are not equal along these coordinates (dimensions): 'lon' ('lon',) The recommendation is to set join explicitly for this case.\n",
      "  ds_all = xr.concat(ds_list, dim=\"time\")\n",
      "/tmp/ipykernel_2553597/1182777592.py:17: FutureWarning: In a future version of xarray the default value for join will change from join='outer' to join='exact'. This change will result in the following ValueError: cannot be aligned with join='exact' because index/labels/sizes are not equal along these coordinates (dimensions): 'lon' ('lon',) The recommendation is to set join explicitly for this case.\n",
      "  ds_all = xr.concat(ds_list, dim=\"time\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = \"hycom\"\n",
    "variables = [\"salinity\", \"water_temp\"]\n",
    "period = \"2015-2024\"\n",
    "area = \"0N_90W_20S_70E\"\n",
    "resolution = \"0.08deg\"\n",
    "\n",
    "folder_path = \"/home/jupyter-daniela/suyana/sources/hycom/\"\n",
    "coarse_grid_file = \"/home/jupyter-daniela/suyana/sources/hycom/2015/hycom_201501.nc\"\n",
    "\n",
    "for var in variables:\n",
    "    ds = open_and_regrid(folder_path, var, coarse_grid_file)\n",
    "    daily = compute_daily(ds, var)\n",
    "    save_netcdf(daily, dataset, var, \"daily\", period, area, resolution)\n",
    "    weekly = compute_weekly(daily)\n",
    "    save_netcdf(weekly, dataset, var, \"weekly\", period, area, resolution)\n",
    "    clim = compute_daily_climatology(daily)\n",
    "    save_netcdf(clim, dataset, var, \"climatology-daily\", period, area, resolution)\n",
    "    anomalies = compute_daily_anomalies(daily, clim)\n",
    "    save_netcdf(anomalies, dataset, var, \"anom-daily\", period, area, resolution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peru_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
